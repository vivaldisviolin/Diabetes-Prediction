{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\ismet\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ismet\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%pip install tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>No_Pation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Urea</th>\n",
       "      <th>Cr</th>\n",
       "      <th>HbA1c</th>\n",
       "      <th>Chol</th>\n",
       "      <th>TG</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>VLDL</th>\n",
       "      <th>BMI</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>502</td>\n",
       "      <td>17975</td>\n",
       "      <td>F</td>\n",
       "      <td>50</td>\n",
       "      <td>4.7</td>\n",
       "      <td>46</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>735</td>\n",
       "      <td>34221</td>\n",
       "      <td>M</td>\n",
       "      <td>26</td>\n",
       "      <td>4.5</td>\n",
       "      <td>62</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>23.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>420</td>\n",
       "      <td>47975</td>\n",
       "      <td>F</td>\n",
       "      <td>50</td>\n",
       "      <td>4.7</td>\n",
       "      <td>46</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>680</td>\n",
       "      <td>87656</td>\n",
       "      <td>F</td>\n",
       "      <td>50</td>\n",
       "      <td>4.7</td>\n",
       "      <td>46</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>504</td>\n",
       "      <td>34223</td>\n",
       "      <td>M</td>\n",
       "      <td>33</td>\n",
       "      <td>7.1</td>\n",
       "      <td>46</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  No_Pation Gender  AGE  Urea  Cr  HbA1c  Chol   TG  HDL  LDL  VLDL  \\\n",
       "0  502      17975      F   50   4.7  46    4.9   4.2  0.9  2.4  1.4   0.5   \n",
       "1  735      34221      M   26   4.5  62    4.9   3.7  1.4  1.1  2.1   0.6   \n",
       "2  420      47975      F   50   4.7  46    4.9   4.2  0.9  2.4  1.4   0.5   \n",
       "3  680      87656      F   50   4.7  46    4.9   4.2  0.9  2.4  1.4   0.5   \n",
       "4  504      34223      M   33   7.1  46    4.9   4.9  1.0  0.8  2.0   0.4   \n",
       "\n",
       "    BMI CLASS  \n",
       "0  24.0     N  \n",
       "1  23.0     N  \n",
       "2  24.0     N  \n",
       "3  24.0     N  \n",
       "4  21.0     N  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#             Uploading Dataset\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"C://Users//ismet//OneDrive//Masaüstü//diabet//Dataset of Diabetes .csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No_Pation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Urea</th>\n",
       "      <th>Cr</th>\n",
       "      <th>HbA1c</th>\n",
       "      <th>Chol</th>\n",
       "      <th>TG</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>VLDL</th>\n",
       "      <th>BMI</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>4.7</td>\n",
       "      <td>46</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>4.5</td>\n",
       "      <td>62</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>4.7</td>\n",
       "      <td>46</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>4.7</td>\n",
       "      <td>46</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34223</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>7.1</td>\n",
       "      <td>46</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No_Pation  Gender  AGE  Urea  Cr  HbA1c  Chol   TG  HDL  LDL  VLDL   BMI  \\\n",
       "0      17975     0.0   50   4.7  46    4.9   4.2  0.9  2.4  1.4   0.5  24.0   \n",
       "1      34221     1.0   26   4.5  62    4.9   3.7  1.4  1.1  2.1   0.6  23.0   \n",
       "2      47975     0.0   50   4.7  46    4.9   4.2  0.9  2.4  1.4   0.5  24.0   \n",
       "3      87656     0.0   50   4.7  46    4.9   4.2  0.9  2.4  1.4   0.5  24.0   \n",
       "4      34223     1.0   33   7.1  46    4.9   4.9  1.0  0.8  2.0   0.4  21.0   \n",
       "\n",
       "   CLASS  \n",
       "0    2.0  \n",
       "1    2.0  \n",
       "2    2.0  \n",
       "3    2.0  \n",
       "4    2.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#       Data Pre-Processing   1\n",
    "\n",
    "\n",
    "df = df.drop('ID', axis = 1)\n",
    "\n",
    "df['Gender'] = df['Gender'].map({'F': 0, 'M': 1})\n",
    "\n",
    "df['CLASS'] = df['CLASS'].map({'P': 0, 'Y': 1, 'N': 2})\n",
    "\n",
    "df.fillna(df.median(), inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature HbA1c - importance: 0.3448758874953945\n",
      "2. feature BMI - importance: 0.23523189866178149\n",
      "3. feature AGE - importance: 0.12407838517640722\n",
      "4. feature Chol - importance: 0.06626205238526324\n",
      "5. feature TG - importance: 0.05104353255952309\n",
      "6. feature No_Pation - importance: 0.0447170126330766\n",
      "7. feature VLDL - importance: 0.03988318068293403\n",
      "8. feature LDL - importance: 0.0291485821694756\n",
      "9. feature Cr - importance: 0.020720230643198407\n",
      "10. feature HDL - importance: 0.02040260372395037\n",
      "11. feature Urea - importance: 0.017032944665291656\n",
      "12. feature Gender - importance: 0.006603689203703722\n"
     ]
    }
   ],
   "source": [
    "#       Data Pre-Processing   2\n",
    "\n",
    "\n",
    "x = df.drop('CLASS', axis=1)\n",
    "y = df['CLASS']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_rf.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "importances = model_rf.feature_importances_\n",
    "\n",
    "\n",
    "x_train_df = pd.DataFrame(x_train, columns=df.drop('CLASS', axis=1).columns)\n",
    "\n",
    "\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(x_train_df.shape[1]):\n",
    "    print(f\"{f + 1}. feature {x_train_df.columns[sorted_indices[f]]} - importance: {importances[sorted_indices[f]]}\")\n",
    "\n",
    "\n",
    "x_train = np.delete(x_train, [7,10,9,4,8,3,1], axis=1)\n",
    "x_test = np.delete(x_test, [7,10,9,4,8,3,1], axis=1)\n",
    "\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=3)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ismet\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,203</span> (28.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,203\u001b[0m (28.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,203</span> (28.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,203\u001b[0m (28.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating Model\n",
    "model = Sequential()\n",
    "\n",
    "# Input Layer\n",
    "model.add(Dense(units=128, activation='relu', input_dim=x_train.shape[1]))\n",
    "\n",
    "# First Hidden Layer\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "\n",
    "# Second Hidden Layer\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "# Compiling Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of Model \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7891 - loss: 0.9860 - val_accuracy: 0.8650 - val_loss: 0.6558\n",
      "Epoch 2/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8335 - loss: 0.8544 - val_accuracy: 0.8600 - val_loss: 0.4107\n",
      "Epoch 3/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8526 - loss: 0.6549 - val_accuracy: 0.8700 - val_loss: 0.3798\n",
      "Epoch 4/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8758 - loss: 0.5511 - val_accuracy: 0.8650 - val_loss: 0.3668\n",
      "Epoch 5/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8581 - loss: 0.5544 - val_accuracy: 0.8750 - val_loss: 0.3384\n",
      "Epoch 6/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8835 - loss: 0.4964 - val_accuracy: 0.8950 - val_loss: 0.3204\n",
      "Epoch 7/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8961 - loss: 0.4467 - val_accuracy: 0.8850 - val_loss: 0.3175\n",
      "Epoch 8/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9293 - loss: 0.3611 - val_accuracy: 0.9150 - val_loss: 0.3013\n",
      "Epoch 9/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9278 - loss: 0.3170 - val_accuracy: 0.9200 - val_loss: 0.2940\n",
      "Epoch 10/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9105 - loss: 0.3214 - val_accuracy: 0.9250 - val_loss: 0.2841\n",
      "Epoch 11/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9356 - loss: 0.2387 - val_accuracy: 0.9150 - val_loss: 0.3036\n",
      "Epoch 12/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9270 - loss: 0.2732 - val_accuracy: 0.9350 - val_loss: 0.2612\n",
      "Epoch 13/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9342 - loss: 0.2378 - val_accuracy: 0.9300 - val_loss: 0.2514\n",
      "Epoch 14/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9415 - loss: 0.1983 - val_accuracy: 0.9300 - val_loss: 0.2462\n",
      "Epoch 15/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9554 - loss: 0.1614 - val_accuracy: 0.9200 - val_loss: 0.2461\n",
      "Epoch 16/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1331 - val_accuracy: 0.9300 - val_loss: 0.2343\n",
      "Epoch 17/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1254 - val_accuracy: 0.9400 - val_loss: 0.2261\n",
      "Epoch 18/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9544 - loss: 0.1345 - val_accuracy: 0.9400 - val_loss: 0.2091\n",
      "Epoch 19/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.1125 - val_accuracy: 0.9450 - val_loss: 0.2022\n",
      "Epoch 20/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9525 - loss: 0.1193 - val_accuracy: 0.9350 - val_loss: 0.2027\n",
      "Epoch 21/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9401 - loss: 0.1315 - val_accuracy: 0.9450 - val_loss: 0.1913\n",
      "Epoch 22/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.0896 - val_accuracy: 0.9450 - val_loss: 0.1813\n",
      "Epoch 23/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.0974 - val_accuracy: 0.9450 - val_loss: 0.1811\n",
      "Epoch 24/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9641 - loss: 0.0933 - val_accuracy: 0.9450 - val_loss: 0.1744\n",
      "Epoch 25/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.0992 - val_accuracy: 0.9450 - val_loss: 0.1718\n",
      "Epoch 26/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.1053 - val_accuracy: 0.9500 - val_loss: 0.1606\n",
      "Epoch 27/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.0847 - val_accuracy: 0.9350 - val_loss: 0.1724\n",
      "Epoch 28/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.0782 - val_accuracy: 0.9450 - val_loss: 0.1597\n",
      "Epoch 29/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.0775 - val_accuracy: 0.9500 - val_loss: 0.1454\n",
      "Epoch 30/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.0752 - val_accuracy: 0.9450 - val_loss: 0.1504\n",
      "Epoch 31/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.0789 - val_accuracy: 0.9450 - val_loss: 0.1466\n",
      "Epoch 32/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.0627 - val_accuracy: 0.9500 - val_loss: 0.1441\n",
      "Epoch 33/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9637 - loss: 0.0663 - val_accuracy: 0.9500 - val_loss: 0.1323\n",
      "Epoch 34/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9709 - loss: 0.0614 - val_accuracy: 0.9500 - val_loss: 0.1316\n",
      "Epoch 35/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9537 - loss: 0.0810 - val_accuracy: 0.9500 - val_loss: 0.1327\n",
      "Epoch 36/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9687 - loss: 0.0593 - val_accuracy: 0.9500 - val_loss: 0.1303\n",
      "Epoch 37/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9505 - loss: 0.0718 - val_accuracy: 0.9500 - val_loss: 0.1260\n",
      "Epoch 38/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9726 - loss: 0.0488 - val_accuracy: 0.9500 - val_loss: 0.1291\n",
      "Epoch 39/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.0600 - val_accuracy: 0.9500 - val_loss: 0.1163\n",
      "Epoch 40/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0565 - val_accuracy: 0.9500 - val_loss: 0.1137\n",
      "Epoch 41/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9681 - loss: 0.0453 - val_accuracy: 0.9500 - val_loss: 0.1208\n",
      "Epoch 42/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.0583 - val_accuracy: 0.9500 - val_loss: 0.1135\n",
      "Epoch 43/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.0685 - val_accuracy: 0.9500 - val_loss: 0.1293\n",
      "Epoch 44/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.0603 - val_accuracy: 0.9500 - val_loss: 0.1233\n",
      "Epoch 45/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.0672 - val_accuracy: 0.9500 - val_loss: 0.1177\n",
      "Epoch 46/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9736 - loss: 0.0407 - val_accuracy: 0.9500 - val_loss: 0.1084\n",
      "Epoch 47/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9715 - loss: 0.0451 - val_accuracy: 0.9500 - val_loss: 0.0989\n",
      "Epoch 48/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.0726 - val_accuracy: 0.9500 - val_loss: 0.1254\n",
      "Epoch 49/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9692 - loss: 0.0586 - val_accuracy: 0.9500 - val_loss: 0.1041\n",
      "Epoch 50/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0766 - val_accuracy: 0.9550 - val_loss: 0.1049\n",
      "Epoch 51/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.0818 - val_accuracy: 0.9400 - val_loss: 0.1505\n",
      "Epoch 52/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.1175 - val_accuracy: 0.9500 - val_loss: 0.1279\n",
      "Epoch 53/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9645 - loss: 0.0929 - val_accuracy: 0.9500 - val_loss: 0.0960\n",
      "Epoch 54/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9656 - loss: 0.0601 - val_accuracy: 0.9550 - val_loss: 0.0989\n",
      "Epoch 55/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9655 - loss: 0.0654 - val_accuracy: 0.9550 - val_loss: 0.1093\n",
      "Epoch 56/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.0548 - val_accuracy: 0.9500 - val_loss: 0.0983\n",
      "Epoch 57/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.0581 - val_accuracy: 0.9500 - val_loss: 0.1047\n",
      "Epoch 58/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9741 - loss: 0.0376 - val_accuracy: 0.9500 - val_loss: 0.0930\n",
      "Epoch 59/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.0412 - val_accuracy: 0.9500 - val_loss: 0.1029\n",
      "Epoch 60/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.0494 - val_accuracy: 0.9500 - val_loss: 0.0926\n",
      "Epoch 61/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9673 - loss: 0.0374 - val_accuracy: 0.9500 - val_loss: 0.0966\n",
      "Epoch 62/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9725 - loss: 0.0370 - val_accuracy: 0.9500 - val_loss: 0.0965\n",
      "Epoch 63/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9672 - loss: 0.0428 - val_accuracy: 0.9500 - val_loss: 0.0821\n",
      "Epoch 64/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9748 - loss: 0.0375 - val_accuracy: 0.9500 - val_loss: 0.0963\n",
      "Epoch 65/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.0432 - val_accuracy: 0.9500 - val_loss: 0.0848\n",
      "Epoch 66/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9672 - loss: 0.0402 - val_accuracy: 0.9500 - val_loss: 0.0940\n",
      "Epoch 67/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9765 - loss: 0.0345 - val_accuracy: 0.9500 - val_loss: 0.0890\n",
      "Epoch 68/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9690 - loss: 0.0358 - val_accuracy: 0.9500 - val_loss: 0.0868\n",
      "Epoch 69/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9668 - loss: 0.0390 - val_accuracy: 0.9500 - val_loss: 0.0910\n",
      "Epoch 70/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9655 - loss: 0.0363 - val_accuracy: 0.9500 - val_loss: 0.0826\n",
      "Epoch 71/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.0441 - val_accuracy: 0.9500 - val_loss: 0.0932\n",
      "Epoch 72/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.0447 - val_accuracy: 0.9500 - val_loss: 0.0890\n",
      "Epoch 73/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9626 - loss: 0.0476 - val_accuracy: 0.9500 - val_loss: 0.0814\n",
      "Epoch 74/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.0412 - val_accuracy: 0.9500 - val_loss: 0.0963\n",
      "Epoch 75/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9733 - loss: 0.0344 - val_accuracy: 0.9500 - val_loss: 0.0811\n",
      "Epoch 76/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9693 - loss: 0.0427 - val_accuracy: 0.9500 - val_loss: 0.0856\n",
      "Epoch 77/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9706 - loss: 0.0384 - val_accuracy: 0.9500 - val_loss: 0.0828\n",
      "Epoch 78/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9677 - loss: 0.0367 - val_accuracy: 0.9500 - val_loss: 0.0869\n",
      "Epoch 79/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9743 - loss: 0.0375 - val_accuracy: 0.9500 - val_loss: 0.0875\n",
      "Epoch 80/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9648 - loss: 0.0432 - val_accuracy: 0.9500 - val_loss: 0.0855\n",
      "Epoch 81/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9554 - loss: 0.0429 - val_accuracy: 0.9500 - val_loss: 0.0871\n",
      "Epoch 82/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9707 - loss: 0.0323 - val_accuracy: 0.9500 - val_loss: 0.0737\n",
      "Epoch 83/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.0307 - val_accuracy: 0.9500 - val_loss: 0.0837\n",
      "Epoch 84/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9575 - loss: 0.0423 - val_accuracy: 0.9500 - val_loss: 0.0850\n",
      "Epoch 85/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9732 - loss: 0.0353 - val_accuracy: 0.9500 - val_loss: 0.0760\n",
      "Epoch 86/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9725 - loss: 0.0363 - val_accuracy: 0.9500 - val_loss: 0.0941\n",
      "Epoch 87/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0425 - val_accuracy: 0.9550 - val_loss: 0.0722\n",
      "Epoch 88/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9729 - loss: 0.0332 - val_accuracy: 0.9550 - val_loss: 0.0831\n",
      "Epoch 89/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9704 - loss: 0.0367 - val_accuracy: 0.9550 - val_loss: 0.0714\n",
      "Epoch 90/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9695 - loss: 0.0389 - val_accuracy: 0.9600 - val_loss: 0.0681\n",
      "Epoch 91/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9825 - loss: 0.0303 - val_accuracy: 0.9550 - val_loss: 0.0783\n",
      "Epoch 92/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9752 - loss: 0.0319 - val_accuracy: 0.9550 - val_loss: 0.0817\n",
      "Epoch 93/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9734 - loss: 0.0287 - val_accuracy: 0.9550 - val_loss: 0.0780\n",
      "Epoch 94/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9701 - loss: 0.0334 - val_accuracy: 0.9550 - val_loss: 0.0866\n",
      "Epoch 95/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9631 - loss: 0.0400 - val_accuracy: 0.9550 - val_loss: 0.0774\n",
      "Epoch 96/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9740 - loss: 0.0321 - val_accuracy: 0.9500 - val_loss: 0.1026\n",
      "Epoch 97/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9720 - loss: 0.0294 - val_accuracy: 0.9550 - val_loss: 0.0744\n",
      "Epoch 98/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9673 - loss: 0.0393 - val_accuracy: 0.9550 - val_loss: 0.0800\n",
      "Epoch 99/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.0250 - val_accuracy: 0.9600 - val_loss: 0.0825\n",
      "Epoch 100/1000\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9718 - loss: 0.0259 - val_accuracy: 0.9650 - val_loss: 0.0691\n"
     ]
    }
   ],
   "source": [
    "# Adding Early Stopping, Creating A Balance Between Classes And Training Model \n",
    "\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.array([0, 1, 2]), y=y_train)\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train_one_hot,\n",
    "    epochs=1000, batch_size=32,\n",
    "    validation_data=(x_test, y_test_one_hot),\n",
    "    callbacks=[early_stopping],\n",
    "    class_weight=class_weights_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9655 - loss: 0.0633\n",
      "Test Loss: 0.06810420006513596, Test Accuracy: 0.9599999785423279\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1ece876e5a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And Results\n",
    "\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test_one_hot)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_acc}')\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "y_test_classes = np.argmax(y_test_one_hot, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['P', 'Y', 'N'])\n",
    "disp.plot(cmap='viridis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
